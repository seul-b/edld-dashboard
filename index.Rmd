---
title: "Eye Tracking Dashboard"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    social: menu
    source_code: embed
    vertical_layout: scroll
    theme:
      bootswatch: journal
    runtime: shiny
    knit: rmarkdown::render
---


```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE)
require(DT)
require(readr)
require(tidyverse)
require(data.table)
require(ggplot2)
require(purrr)
require(ggmap)
require(graphics)
require(scanpath)
require(flexdashboard)
require(tidyverse)
require(mice)
require(DT)
require(dplyr)
require(readr)
require(png)

aq <- read_csv("data/AQ_SubScales.csv")
exp <- read_csv("data/datadryad_clear98_aq.csv")

df <- list.files(path = "data/dataset_normalised_5mins/BROWSE",
                 pattern = "*.csv",
                 full.names = TRUE) %>%
  lapply(read_csv) %>%
  bind_rows
```


Home
=============

### Hello!

Welcome to my final project of EDLD 652: Data Visualization class. <br>

My name is Seulbi Lee, and I'm a second year PhD student in Special Education program. One of my projects that I'm planning is related to eye tracking research to better understand struggling readers' comprehension, so I wanted to include two eye tracking datasets for this project. <br>


The first dataset ("Browsing on Screen") consists of raw gaze coordinates (x-y) of 24 participants while performing online activities during five minutes. The eye movements were recorded using Tobii X2-30 eye tracker and Tobii Pro Studio software. In my project, only Browsing activity is included. Original data can be found at https://www.kaggle.com/datasets/namratasri01/eye-movement-data-set-for-desktop-activities <br>


The second dataset ("Face Viewing Experiment") is from a published study titled "A relationship between Autism-Spectrum Quotient and face viewing behavior in 98 participants". The eye movements were recorded using Eye Link 1000 Plus and analyzed with SR Researchâ€™s Eyelink software. Original data and article can be found at https://doi.org/10.5061/dryad.zpc866t5c


### These things will be revised for the final product: 
> 1) 'References' on tabs 1 and 2 should be center aligned;
> 2) The color of geom_point on tab 2 will be changed so that they are more noticeble; 
> 3) The bug that last tab appears on the home tab when opening will be managed; 
> 4) Indentations will be added for descriptions; and
> 5) There will be added another visualization on tab 3.

If there are additional points that I would need to revise, please let me know. Thank you for reviewing my draft! 



Browsing on Screen 1
=============

The eye gaze path plots show us each participant's eye movement while browsing on screen for five minutes. Different colors indicate different sets (screens) they were browsing. 


Row
---------------------------------------------------------------
### Eye Gaze Path

```{r, echo=FALSE, fig.height=10, fig.width=12}
diff <- tail(df$timestamp, 214127)
diff <- append(diff, NA)
df$diff <- diff

df$duration <- df$diff - df$timestamp

df <- df[df$duration >= 0,]

df <- df[rowSums(is.na(df)) != ncol(df),]

p <- plot_scanpaths(df, duration ~ x + y | participant, set)

g <- p + ggplot2::theme(legend.position = "none")

g
```

Row
---------------------------------------------------------------
<p style="text-align: center;">**References**</p>
<br>
Srivastava, N., Newn, J., & Velloso, E. (2018). Combining Low and Mid-Level Gaze Features for Desktop Activity Recognition. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 2(4), 189.




Browsing on Screen 2
=============

The screenshots of websites are not what they were looking; however, I added each screenshot to help you understand what regions on the webpage each participant was gazing (e.g., title, content, sidebar, etc.). <br>



Row {.tabset}
---------------------------------------------------------------
### Set A 

``` {r, echo=FALSE, fig.height=10, fig.width=12}
img.A <- png::readPNG("data/web.A.png")

df.A <- df[df$set == 'A', ]

p.A <- ggplot(df.A, aes(x = x, y = y, fill = duration)) +
  ggpubr::background_image(img.A) +
  geom_point(pch = 21) +
  facet_wrap( ~ participant)

p.A
```

### Set B

``` {r, echo=FALSE, fig.height=10, fig.width=12}
img.B <- png::readPNG("data/web.B.png")

df.B <- df[df$set == 'B', ]

p.B <- ggplot(df.B, aes(x = x, y = y, fill = duration)) +
  ggpubr::background_image(img.B) +
  geom_point(pch = 21) +
  facet_wrap( ~ participant)

p.B
```

### Set C

``` {r, echo=FALSE, fig.height=10, fig.width=12}
img.C <- png::readPNG("data/web.C.png")

df.C <- df[df$set == 'C', ]

p.C <- ggplot(df.C, aes(x = x, y = y, fill = duration)) +
  ggpubr::background_image(img.C) +
  geom_point(pch = 21) +
  facet_wrap( ~ participant)

p.C
```


Row
---------------------------------------------------------------
<p style="text-align: center;">**References**</p>
<br>
Oregon Ducks. (2022, October 25). In Wikipedia. https://en.wikipedia.org/wiki/Oregon_Ducks
<br>
Oregon.gov. (n.d.). Equity and Student Success. https://www.oregon.gov/highered/policy-collaboration/Pages/equity-success.aspx
<br>
Statista.com. (n.d.). Daily Infographics: Global stories vividly visualized. https://www.statista.com/chartoftheday/


Face Viewing Experiment 1 
=============
Row
---------------------------------------------------------------
### UNDER CONSTRUCTION

```{r, eval=TRUE, include=FALSE}



```



Face Viewing Experiment 2
=============

This plot shows how each scale of AQ is related to the time spent areas of interest (i.e., face in this experiment) while an interlocutor was talking. <br>

[Consideration 1: include the total score or not? <br>
Consideration 2: differentiate and include plots for the time spent on eyes and mouth or not?]

Column 
---------------------------------------------------------------

### Table

```{r, echo=FALSE}

aq <- read_csv("data/AQ_SubScales.csv")
exp <- read_csv("data/datadryad_clear98_aq.csv")

exp.m <- exp[c(13, 18)]
exp.m <- aggregate(exp.m$PC_Off, list(exp.m$Code), FUN=mean)
exp.m <- exp.m %>% 
  rename('Code' = 'Group.1',
         'Off' = 'x')
exp.m <- unique(exp.m)

aq <- rename(aq, Code = code)
exp <- left_join(exp, aq, by="Code")
exp.aq <- exp[c(18, 21:26)]
exp.aq <- unique(exp.aq)

exp.c <-left_join(exp.m, exp.aq, by=c("Code"))
exp.c <- exp.c %>% 
  pivot_longer(c(4:8),
               names_to = "scale",
               values_to = "score")

ggplot(exp.c, aes(Off, score, colour = scale)) +
  geom_point(alpha = .5, shape = 20) +
  xlab('Time Gazed Out Of Face') +
  ylab('AQ Score') +
  geom_smooth(method=lm, se = FALSE)+
  scale_y_continuous(breaks=c(0,2,4,6,8,10))

```

Row
---------------------------------------------------------------
<p style="text-align: center;">**References**</p>
<br>
Wegner-Clemens, Kira, Rennig, Johannes, & Beauchamp, Michael S. (2020). A relationship between Autism-Spectrum Quotient and face viewing behavior in 98 participants [Data set]. https://doi.org/10.5061/dryad.zpc866t5c